@InProceedings{C2,
  author = 	 "Jones, C.D. and Smith, A.B. and Roberts, E.F.",
  title =        "Article Title",
  booktitle =        "Proceedings Title",
  organization = "IEEE",
  year = 	 "2003",
  volume = 	 "II",
  pages = 	 "803-806"
}

@INPROCEEDINGS{990517,
  author={P. {Viola} and M. {Jones}},
  booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
  title={Rapid object detection using a boosted cascade of simple features}, 
  year={2001},
  volume={1},
  number={},
  pages={I-I},
  abstract={This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
  keywords={object detection;image classification;image representation;learning (artificial intelligence);feature extraction;rapid object detection;boosted simple feature cascade;machine learning;visual object detection;image processing;image representation;integral image;AdaBoost;classifiers;background regions;object specific focus-of-attention mechanism;statistical guarantees;face detection;real-time applications;Object detection;Face detection;Pixel;Detectors;Filters;Machine learning;Image representation;Focusing;Skin;Robustness},
  doi={10.1109/CVPR.2001.990517},
  ISSN={1063-6919},
  month={Dec},}

@online{cartoonset,
	author = {Google},
	title = {Cartoon Set: An Image Dataset of Random Characters},
	url = {https://google.github.io/cartoonset/index.html},
	urldate = {2020-11-30}
}

@INPROCEEDINGS{7410776,
  author={S. {Yang} and P. {Luo} and C. {Loy} and X. {Tang}},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={From Facial Parts Responses to Face Detection: A Deep Learning Approach}, 
  year={2015},
  volume={},
  number={},
  pages={3676-3684},
  abstract={In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically, our method achieves a high recall rate of 90.99% on the challenging FDDB benchmark, outperforming the state-of-the-art method [23] by a large margin of 2.91%. Importantly, we consider finding faces from a new perspective through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect faces under severe occlusion and unconstrained pose variation, which are the main difficulty and bottleneck of most existing face detection approaches. We show that despite the use of DCN, our network can achieve practical runtime speed.},
  keywords={face recognition;learning (artificial intelligence);facial parts responses;face detection;deep learning approach;novel deep convolutional network;DCN;FDDB;PASCAL Face;AFW;scoring facial parts;spatial structure;spatial arrangement;unconstrained pose variation;Face;Face detection;Proposals;Hair;Mouth;Detectors;Nose},
  doi={10.1109/ICCV.2015.419},
  ISSN={2380-7504},
  month={Dec},}

@INPROCEEDINGS{8549735,
  author={K. {Candra Kirana} and S. {Wibawanto} and H. {Wahyu Herwanto}},
  booktitle={2018 International Seminar on Application for Technology of Information and Communication}, 
  title={Facial Emotion Recognition Based on Viola-Jones Algorithm in the Learning Environment}, 
  year={2018},
  volume={},
  number={},
  pages={406-410},
  abstract={An emotion is a trigger of learning success, so the learning should be adapting to the students' emotions. The most of popular approach is the acquisition of facial-based features. Therefore, we present facial emotion recognition based on the Viola-Jones Algorithm in the learning environment. Basically, the Viola-Jones algorithm is a face detection algorithm. However, we use facial-based features to detect face and recognize emotion, thus we applied rectangular feature and cascading AdaBoost algorithm which are the main concept of the Viola-Jones Algorithm in those both of process. In this study, we compare accuracy, precision, recall, and time-consuming of the Viola-Jones algorithm and our previous methods [1] using 50 UM's learning images in student emotion recognition. The accuracy, precision, recall, and time-consuming of Viola-Jones algorithm reach 0.74, 0.73, 0.76 and 15 seconds per frame, whereas our previous methods [1] reach 0.46, 0.48, 0.52, and 42 seconds per frame. In emotional recognition, we can conclude that the viola jones algorithm is superior to our previous research.},
  keywords={emotion recognition;face recognition;feature extraction;learning (artificial intelligence);object detection;rectangular feature;student emotion recognition;viola jones algorithm;facial emotion recognition;learning environment;facial-based features;face detection algorithm;time 42.0 s;time 0.74 s;time 0.73 s;time 0.76 s;time 15.0 s;time 0.46 s;time 0.48 s;time 0.52 s;Emotion recognition;Classification algorithms;Face detection;Face;Seminars;Feature extraction;Biological neural networks;facial recognition;emotion recognition;learning emotion;Viola-Jones algorithm},
  doi={10.1109/ISEMANTIC.2018.8549735},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{8806572,
  author={W. {LU} and M. {YANG}},
  booktitle={2019 International Conference on Robots   Intelligent System (ICRIS)}, 
  title={Face Detection Based on Viola-Jones Algorithm Applying Composite Features}, 
  year={2019},
  volume={},
  number={},
  pages={82-85},
  abstract={Viola-Jones' face detection algorithm was jointly proposed by Paul Viola and Michael Jones. Although it realized face real-time detection to some extent, its false detection rate is not low. Because the block features in the Viola-Jones algorithm can't handle purely rigid objects, such as chopsticks and cups, so if there are rigid objects in the face image, Viola-Jones' face detection algorithm is prone to generate false detection of faces. In this paper, we propose to apply the composite features based on Viola-Jones algorithm to improve the above problems, and prove the feasibility of this method through experiments.},
  keywords={face recognition;object detection;Viola-Jones' face detection algorithm;Paul Viola;Michael Jones;false detection rate;face image;Viola-Jones algorithm;composite features;face real-time detection;Face;Feature extraction;Face recognition;Face detection;Classification algorithms;Compounds;Linear discriminant analysis;Viola-Jones;Compound Features;Face Detection},
  doi={10.1109/ICRIS.2019.00029},
  ISSN={},
  month={June},}

@INPROCEEDINGS{6619290,
  author={Y. {Sun} and X. {Wang} and X. {Tang}},
  booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Deep Convolutional Network Cascade for Facial Point Detection}, 
  year={2013},
  volume={},
  number={},
  pages={3476-3483},
  abstract={We propose a new approach for estimation of the positions of facial key points with three-level carefully designed convolutional networks. At each level, the outputs of multiple networks are fused for robust and accurate estimation. Thanks to the deep structures of convolutional networks, global high-level features are extracted over the whole face region at the initialization stage, which help to locate high accuracy key points. There are two folds of advantage for this. First, the texture context information over the entire face is utilized to locate each key point. Second, since the networks are trained to predict all the key points simultaneously, the geometric constraints among key points are implicitly encoded. The method therefore can avoid local minimum caused by ambiguity and data corruption in difficult image samples due to occlusions, large pose variations, and extreme lightings. The networks at the following two levels are trained to locally refine initial predictions and their inputs are limited to small regions around the initial predictions. Several network structures critical for accurate and robust facial point detection are investigated. Extensive experiments show that our approach outperforms state-of-the-art methods in both detection accuracy and reliability.},
  keywords={face recognition;feature extraction;hidden feature removal;image texture;pose estimation;facial keypoint detection accuracy;position estimation;deep convolutional network cascade;three-level convolutional networks;global high-level feature extraction;face region;initialization stage;high accuracy keypoint location;texture context information;geometric constraints;data corruption;image samples;occlusions;pose variations;convolutional network structures;robust facial point detection;reliability;Face;Feature extraction;Convolutional codes;Shape;Training;Detectors;Accuracy;Convolutional Network;Facial Point Detection},
  doi={10.1109/CVPR.2013.446},
  ISSN={1063-6919},
  month={June},}

@ARTICLE{7553523,
  author={K. {Zhang} and Z. {Zhang} and Z. {Li} and Y. {Qiao}},
  journal={IEEE Signal Processing Letters}, 
  title={Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks}, 
  year={2016},
  volume={23},
  number={10},
  pages={1499-1503},
  abstract={Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.},
  keywords={data mining;face recognition;learning (artificial intelligence);annotated facial landmark;detection benchmark;detection dataset;WIDER FACE benchmark;state-of-the-art technique;online hard sample mining strategy;coarse-to-fine manner;landmark location prediction;face location prediction;deep cascaded multitask framework;deep learning approach;unconstrained environment;multitask cascaded convolutional network;joint face detection and alignment;Face;Face detection;Training;Convolution;Detectors;Computer architecture;Benchmark testing;Cascaded convolutional neural network (CNN);face alignment;face detection},
  doi={10.1109/LSP.2016.2603342},
  ISSN={1558-2361},
  month={Oct},}

